{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Libraries:\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000002109CF9AA00> and <tensorflow.python.keras.layers.core.Dropout object at 0x000002109CFCF2E0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000002109CFCF7C0> and <tensorflow.python.keras.layers.advanced_activations.Softmax object at 0x000002109CFDF040>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000002109CF9AA00> and <tensorflow.python.keras.layers.core.Flatten object at 0x000002109CF9A430>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x000002109CFCF7C0> and <tensorflow.python.keras.layers.core.Dropout object at 0x000002109CFCF2E0>).\n"
     ]
    }
   ],
   "source": [
    "# Load the Trained Model:\n",
    "\n",
    "model = tf.keras.models.load_model(\"my_mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Transformations being done on the uploaded image for getting more accurate prediction:\n",
    "\n",
    "img = cv.imread('./8.jpg')\n",
    "cv.imshow('Original', img)\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "cv.imshow('Grayscaled', img_gray)\n",
    "img_inverted = cv.bitwise_not(img_gray)\n",
    "cv.imshow('Inverted', img_inverted)\n",
    "img_resized = cv.resize(img_inverted, (28, 28))\n",
    "cv.imshow('Resized', img_resized)\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Converting the Image into a Numpy Array so as to feed it to the trained model for prediction:\n",
    "\n",
    "image_arr = np.asarray(img_resized)\n",
    "print(image_arr.shape)\n",
    "image_reshaped = image_arr.reshape((1, 28, 28))\n",
    "print(image_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(image_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number present in the image uploaded:  8\n"
     ]
    }
   ],
   "source": [
    "# Prediction of the Number present in the Image:\n",
    "\n",
    "print(\"The number present in the image uploaded: \", np.argmax(model.predict(image_reshaped)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Padding to convert image to square image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before padding:  (225, 225, 3)\n",
      "Height before padding:  225\n",
      "Width before padding:  225\n",
      "Shape after padding:  (225, 225, 3)\n",
      "Array Shape:  (28, 28)\n",
      "Array Shape after Reshaping:  (1, 28, 28)\n",
      "Number Present in Image:  8\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape before padding: \", img.shape)\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "print(\"Height before padding: \", height)\n",
    "print(\"Width before padding: \", width)\n",
    "\n",
    "if width >= height:\n",
    "    if (width-height)%2 == 0:\n",
    "        padding = cv.copyMakeBorder(img, int((width-height)/2), int((width-height)/2), 0, 0, cv.BORDER_CONSTANT,value=(255, 255, 255))\n",
    "    else:\n",
    "        padding = cv.copyMakeBorder(img, int((width-height)/2), int((width-height)/2)+1, 0, 0, cv.BORDER_CONSTANT,value=(255, 255, 255))\n",
    "else:\n",
    "    if (height-width)%2 == 0:\n",
    "        padding = cv.copyMakeBorder(img, 0, 0, int((height-width)/2), int((height-width)/2), cv.BORDER_CONSTANT,value=(255, 255, 255))\n",
    "    else:\n",
    "        padding = cv.copyMakeBorder(img, 0, 0, int((height-width)/2)+1, int((height-width)/2), cv.BORDER_CONSTANT,value=(255, 255, 255))\n",
    "print(\"Shape after padding: \", padding.shape)\n",
    "# cv.imshow(\"Padded Image\", padding)\n",
    "\n",
    "img_gray = cv.cvtColor(padding, cv.COLOR_RGB2GRAY)\n",
    "# cv.imshow('Grayscaled', img_gray)\n",
    "img_inverted = cv.bitwise_not(img_gray)\n",
    "# cv.imshow('Inverted', img_inverted)\n",
    "newimg = cv.resize(img_inverted, (28, 28))\n",
    "# cv.imshow('Resized', newimg)\n",
    "\n",
    "image = np.asarray(newimg)\n",
    "print(\"Array Shape: \", image.shape)\n",
    "image_r = image.reshape((1, 28, 28))\n",
    "print(\"Array Shape after Reshaping: \", image_r.shape)\n",
    "\n",
    "pred = np.argmax(model.predict(image_r))\n",
    "print(\"Number Present in Image: \", str(pred))\n",
    "\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
